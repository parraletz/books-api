# Demo: Kubernetes Autoscaling con Books API

Este es un script paso a paso para demostrar el autoescalado de Kubernetes usando el endpoint `/stress`.

## üìã Pre-requisitos

- Cluster de Kubernetes funcionando
- `kubectl` configurado
- `metrics-server` instalado
- Books API desplegado con HPA habilitado

## üé¨ Script de Demostraci√≥n

### Paso 1: Preparar el entorno

```bash
# 1. Verificar que el cluster est√° corriendo
kubectl cluster-info

# 2. Verificar que metrics-server funciona
kubectl top nodes
kubectl top pods

# 3. Verificar el deployment de books-api
kubectl get deployment books-api

# 4. Verificar el HPA
kubectl get hpa books-api
# Deber√≠as ver: TARGETS con valores como "15%/80%"
```

### Paso 2: Configurar port-forward

```bash
# En una terminal dedicada, mant√©n este comando corriendo
kubectl port-forward svc/books-api 3000:80
```

### Paso 3: Verificar estado inicial

```bash
# En otra terminal

# Ver pods actuales (deber√≠a haber 2)
kubectl get pods -l app.kubernetes.io/name=books-api

# Ver uso actual de CPU
kubectl top pods -l app.kubernetes.io/name=books-api

# Probar que la API funciona
curl http://localhost:3000/
```

### Paso 4: Configurar monitoreo

Abre 3 terminales adicionales (puedes usar tmux o screen):

**Terminal 1 - Pods:**
```bash
watch -n 2 'kubectl get pods -l app.kubernetes.io/name=books-api'
```

**Terminal 2 - HPA:**
```bash
watch -n 2 'kubectl get hpa books-api'
```

**Terminal 3 - M√©tricas de CPU:**
```bash
watch -n 5 'kubectl top pods -l app.kubernetes.io/name=books-api'
```

### Paso 5: Generar carga ligera

```bash
# Carga baja que NO deber√≠a causar escalado
curl "http://localhost:3000/stress?duration=5000&intensity=low"

# Espera 30 segundos y observa las m√©tricas
# CPU deber√≠a mantenerse bajo 80%
```

### Paso 6: Generar carga que cause escalado

```bash
# Iniciar script de carga continua
./scripts/stress-test.sh http://localhost:3000 15000 high 10
```

**Qu√© observar:**

1. **Primeros 30 segundos:** CPU empieza a subir en las m√©tricas
2. **1-2 minutos:** CPU supera el 80% consistentemente
3. **2-3 minutos:** HPA detecta la alta carga y empieza a escalar
4. **3-4 minutos:** Nuevos pods aparecen en estado "ContainerCreating"
5. **4-5 minutos:** Nuevos pods pasan a "Running" y empiezan a recibir tr√°fico
6. **5+ minutos:** Carga se distribuye, CPU promedio baja

### Paso 7: Observar el escalado

```bash
# Ver eventos del HPA
kubectl describe hpa books-api

# Ver logs de un pod espec√≠fico
kubectl logs -f <pod-name>

# Ver todos los pods y su estado
kubectl get pods -l app.kubernetes.io/name=books-api -o wide
```

### Paso 8: Detener la carga

```bash
# En la terminal donde corre stress-test.sh
Ctrl + C

# Observa c√≥mo el CPU empieza a bajar
# El scale-down toma 5-10 minutos (configuraci√≥n predeterminada)
```

### Paso 9: Observar scale-down

```bash
# Despu√©s de ~5 minutos sin carga, el HPA empieza a reducir pods
# Observa en la terminal de watch kubectl get pods

# Ver historial de escalado
kubectl describe hpa books-api | grep -A 20 "Events:"
```

## üìä Explicaci√≥n de M√©tricas

### Output del HPA

```
NAME        REFERENCE              TARGETS    MINPODS   MAXPODS   REPLICAS
books-api   Deployment/books-api   180%/80%   2         10        4
```

- **TARGETS:** `180%/80%` significa:
  - Uso actual: 180% (promedio de todos los pods)
  - Target: 80% (objetivo configurado)
  - Como 180% > 80%, el HPA escalar√° UP
  
- **REPLICAS:** N√∫mero actual de pods (aumentar√° hasta maxReplicas)

### Output de kubectl top pods

```
NAME                         CPU(cores)   MEMORY(bytes)
books-api-59f7b8d9b4-abcde   198m         45Mi
books-api-59f7b8d9b4-fghij   195m         44Mi
```

- **CPU(cores):** Uso en millicores (1000m = 1 core)
- Con `requests.cpu: 100m` y usando 198m = 198% de utilizaci√≥n

## üéØ Escenarios de Demo

### Escenario 1: Tr√°fico Normal (No Escala)

```bash
# Simular 2-3 usuarios concurrentes
./scripts/stress-test.sh http://localhost:3000 5000 low 2
```

**Resultado esperado:** CPU < 80%, mantiene 2 pods

### Escenario 2: Tr√°fico Moderado (Escala a 3-4 pods)

```bash
# Simular 5-10 usuarios concurrentes
./scripts/stress-test.sh http://localhost:3000 10000 medium 5
```

**Resultado esperado:** CPU 80-120%, escala a 3-4 pods

### Escenario 3: Tr√°fico Alto (Escala al m√°ximo)

```bash
# Simular 20+ usuarios concurrentes con operaciones pesadas
./scripts/stress-test.sh http://localhost:3000 20000 high 20
```

**Resultado esperado:** CPU > 150%, escala hasta maxReplicas (10 pods)

### Escenario 4: Spike de Tr√°fico

```bash
# Generar un pico s√∫bito
for i in {1..50}; do
  curl "http://localhost:3000/stress?duration=20000&intensity=high" &
done
```

**Resultado esperado:** Escalado r√°pido en respuesta al pico

## üí° Tips para la Presentaci√≥n

### Antes de la demo

1. ‚úÖ Verifica que metrics-server funciona
2. ‚úÖ Prueba el endpoint /stress localmente
3. ‚úÖ Configura las terminales de monitoreo
4. ‚úÖ Ten el script stress-test.sh listo
5. ‚úÖ Anota los comandos clave en un cheatsheet

### Durante la demo

1. üé§ Explica el concepto de HPA primero
2. üìä Muestra el estado inicial (2 pods, CPU baja)
3. üöÄ Ejecuta el script de carga y explica qu√© hace
4. üëÄ Se√±ala las m√©tricas subiendo en las terminales
5. ‚è±Ô∏è Mientras esperas el escalado, explica la configuraci√≥n YAML
6. üéâ Celebra cuando aparezcan nuevos pods
7. üìà Muestra c√≥mo la carga se distribuye
8. ‚¨áÔ∏è Det√©n la carga y explica el scale-down

### Puntos clave a mencionar

- **Tiempo de escalado:** 2-3 minutos (configurable)
- **Tiempo de scale-down:** 5-10 minutos (m√°s conservador para evitar flapping)
- **Basado en m√©tricas:** Usa el uso promedio de CPU de todos los pods
- **L√≠mites de recursos:** Importante definir `requests` y `limits`
- **Production-ready:** Incluye health checks, security context, etc.

## üîß Troubleshooting Durante la Demo

### "El HPA no muestra m√©tricas"

```bash
# Verificar metrics-server
kubectl get deployment metrics-server -n kube-system

# Reinstalar si es necesario
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

### "El HPA no escala"

```bash
# Verificar que los pods tienen requests definidos
kubectl describe pod <pod-name> | grep -A 5 "Requests"

# Verificar eventos del HPA
kubectl describe hpa books-api
```

### "No puedo hacer port-forward"

```bash
# Alternativamente, usa LoadBalancer o Ingress
kubectl get svc books-api

# O crea un servicio temporal
kubectl expose deployment books-api --type=LoadBalancer --port=80 --target-port=3000 --name=books-api-lb
```

## üìù Comandos de Referencia R√°pida

```bash
# Monitoreo
kubectl get hpa -w
kubectl top pods -l app.kubernetes.io/name=books-api --sort-by=cpu
kubectl describe hpa books-api

# Escalar manualmente (para comparar)
kubectl scale deployment books-api --replicas=5

# Ver logs en tiempo real de todos los pods
kubectl logs -f -l app.kubernetes.io/name=books-api --all-containers=true

# Limpiar despu√©s de la demo
kubectl delete hpa books-api
kubectl scale deployment books-api --replicas=2
```

## üéì Conceptos Educativos

### ¬øC√≥mo funciona HPA?

1. **Metrics Server** recopila m√©tricas de CPU/memoria de cada pod
2. **HPA Controller** consulta estas m√©tricas cada 15 segundos (configurable)
3. **Algoritmo de escalado:**
   ```
   deseado = ceil(pods_actuales * (m√©trica_actual / m√©trica_objetivo))
   ```
4. **Cooldown periods:**
   - Scale-up: ~3 minutos sin cambios
   - Scale-down: ~5 minutos sin cambios
5. **Aplica el cambio** modificando el deployment

### Configuraci√≥n en values.yaml

```yaml
autoscaling:
  enabled: true                          # Habilitar HPA
  minReplicas: 2                        # M√≠nimo de pods
  maxReplicas: 10                       # M√°ximo de pods
  targetCPUUtilizationPercentage: 80   # Target: 80% de requests.cpu

resources:
  requests:
    cpu: 100m      # HPA usa este valor como base
  limits:
    cpu: 200m      # L√≠mite m√°ximo por pod
```

## üîó Referencias

- [Kubernetes HPA Docs](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
- [Metrics Server](https://github.com/kubernetes-sigs/metrics-server)
- [HPA Algorithm](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details)
